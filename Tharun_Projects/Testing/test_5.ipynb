{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Reading_csv\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = spark.read.csv(r\"C:\\Users\\tharu\\OneDrive\\Documents\\Employes.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = spark.read.csv(r\"C:\\Users\\tharu\\OneDrive\\Documents\\Department.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join = df_1.join(df_2, df_1.ENAME == df_2.DNAME, \"inner\")\n",
    "print(\"INNER JOIN:\")\n",
    "inner_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_outer_join = df_1.join(df_2, df_1.ENAME == df_2.DNAME, \"outer\")\n",
    "print(\"FULL OUTER JOIN:\")\n",
    "inner_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_1.columns\n",
    "b = df_2.columns\n",
    "for i in range(len(a)):\n",
    "    #print(a[i])\n",
    "    for j in range(len(b)):\n",
    "        print(b[j], end=' ')\n",
    "        #print(a[i],b[j], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'ENAME'\n",
    "selected_column = df_1.select(column_name)\n",
    "column_values = selected_column.rdd.map(lambda x: x[0]).collect()\n",
    "for value in column_values:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_spec = Window.partitionBy(\"DEPTNO\").orderBy(\"SAL\")\n",
    "rank_salary_by_dept = F.rank().over(window_spec)\n",
    "df_ranked_salary = df_1.withColumn(\"RANK\", rank_salary_by_dept)\n",
    "df_ranked_salary.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dense Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window specification\n",
    "window_spec = Window.partitionBy(\"DEPTNO\").orderBy(\"SAL\")\n",
    "\n",
    "dense_rank_salary_by_dept = F.dense_rank().over(window_spec)\n",
    "df_dense_ranked_salary = df_1.withColumn(\"DENSE_RANK\", dense_rank_salary_by_dept)\n",
    "print(\"DataFrame with Dense Rank:\")\n",
    "df_dense_ranked_salary.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row_number_salary_by_dept = F.row_number().over(window_spec)\n",
    "df_row_numbered_salary = df_1.withColumn(\"ROW_NUMBER\", row_number_salary_by_dept)\n",
    "print(\"DataFrame with Row Number:\")\n",
    "df_row_numbered_salary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter data based on a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#filtered_data = df_1.filter(df_1[\"COMM\"].isnotnull() )\n",
    "#filtered_data.show()\n",
    "filtered_data = df_1.filter(df_1[\"COMM\"].isNotNull())\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by department and calculate the average salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_salary_by_dept = df_1.groupBy(\"DEPTNO\").agg(avg(\"SAL\").alias(\"AVG_SALARY\"))\n",
    "avg_salary_by_dept.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort the DataFrame based on a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted_df = df_1.orderBy(\"SAL\", ascending=False)\n",
    "sorted_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Add a new column with a calculated value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_bonus = df_1.withColumn(\"TOTAL_SALARY\", col(\"SAL\") + col(\"COMM\"))\n",
    "df_with_bonus.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_renamed = df_1.withColumnRenamed(\"EMPNO\", \"EmployeeNumber\")\n",
    "df_renamed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_without_comm = df_1.drop(\"COMM\")\n",
    "df_without_comm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1.na.drop()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Describe statistics of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_1.select([\"SAL\", \"COMM\"]).describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_1.select([F.min(\"SAL\"), F.min(\"ENAME\")]).show()\n",
    "df_1.select([F.max(\"SAL\"), F.max(\"ENAME\")]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.select(\"EMPNO\", \"ENAME\", \"JOB\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_1.groupBy(\"DEPTNO\").agg({\"SAL\": \"avg\", \"COMM\": \"sum\"})\n",
    "df_grouped.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_1.orderBy(\"SAL\", ascending=False)\n",
    "df_sorted.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_bonus = df_1.withColumn(\"BONUS\", F.col(\"SAL\") * 0.1)\n",
    "df_with_bonus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed = df_1.withColumnRenamed(\"EMPNO\", \"EmployeeID\").withColumnRenamed(\"ENAME\", \"EmployeeName\")\n",
    "df_renamed.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joined_df = df_1.join(df_2, df_1[\"DEPTNO\"] == df_2[\"DEPTNO\"], \"outer\")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
